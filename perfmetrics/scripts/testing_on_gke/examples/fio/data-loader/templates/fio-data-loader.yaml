# Copyright 2018 The Kubernetes Authors.
# Copyright 2022 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apiVersion: v1
kind: Pod
metadata:
  name: fio-data-loader-{{ .Values.fio.fileSize | lower }}
  {{- if .Values.createUsingGcsfuse }}
  annotations:
    gke-gcsfuse/volumes: "true"
  {{- end }}
spec:
  restartPolicy: Never
  nodeSelector:
    cloud.google.com/gke-ephemeral-storage-local-ssd: "true"
  containers:
  - name: fio-data-loader
    image: ubuntu:24.04
    resources:
      limits:
        cpu: "100"
        memory: 400Gi
      requests:
        cpu: "30"
        memory: 300Gi
    command:
      - "/bin/sh"
      - "-c"
      - |
        # Fail if any of the commands fails.
        set -e
        # Print out the individual commands run.
        set -x

        echo "Install dependencies..."
        apt-get update
        apt-get install -y libaio-dev gcc make git wget

        echo "Installing gcloud ..."
        apt-get update && apt-get install -y apt-transport-https ca-certificates gnupg curl
        curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
        echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
        apt-get update && apt-get install -y google-cloud-cli

        {{ if .Values.preprod }}
        # switch to preprod environment
        gcloud config configurations create preprod || gcloud config configurations activate preprod
        gcloud config set pass_credentials_to_gsutil true
        gcloud config set disable_usage_reporting true
        # preprod endpoint from go/gcs-universes
        gcloud config set api_endpoint_overrides/storage https://storage-preprod-test-unified.googleusercontent.com/storage/v1_preprod/
        # Requires gcloud version Google Cloud SDK 422.0.0 or later.
        gcloud config set storage/json_api_version v1_preprod
        {{ end }}

        echo "Installing fio..."
        git clone -b fio-3.36 https://github.com/axboe/fio.git
        cd fio
        sed -i 's/define \+FIO_IO_U_PLAT_GROUP_NR \+\([0-9]\+\)/define FIO_IO_U_PLAT_GROUP_NR 32/g' stat.h
        ./configure && make && make install
        cd ..

        echo "Generating data for file size: {{ .Values.fio.fileSize }}, file per thread: {{ .Values.fio.filesPerThread }} ..."
        filename=/fio_dataloader_job.fio
        {{ if eq .Values.fio.fileSize "200G" }}
        cat > $filename << EOF
        [global]
        ioengine=libaio
        direct=1
        fadvise_hint=0
        iodepth=64
        invalidate=1
        nrfiles=1
        thread=1
        openfiles=1
        group_reporting=1
        create_serialize=0
        allrandrepeat=1
        numjobs=1
        filename=/local-data/0

        [Workload]
        bs=1M
        filesize=200G
        size=2G
        rw=read
        offset=0
        offset_increment=1%
        EOF
        {{ else }}
        cat > $filename << EOF
        ; -- use nrfiles and rw to CLI args to control readtype and number of files --
        [global]
        ioengine=libaio
        direct=1
        fadvise_hint=0
        iodepth=64
        invalidate=1
        nrfiles={{ .Values.fio.filesPerThread }}
        thread=1
        openfiles=1
        group_reporting=1
        create_serialize=0
        allrandrepeat=0
        file_service_type=random
        numjobs={{ .Values.fio.numThreads }}
        filename_format=\$jobname.\$jobnum/\$filenum

        [Workload]
        directory=/local-data
        bs={{ .Values.fio.blockSize }}
        filesize={{ .Values.fio.fileSize }}
        rw=write
        EOF
        {{ end }}

        fio ${filename} --alloc-size=1048576

        echo "Uploading data to bucket {{ .Values.bucketName }}..."
        {{ if .Values.createUsingGcsfuse }}
        cp -rfv /local-data/* /data/
        {{ else }}
        gcloud storage cp -r /local-data/* gs://{{ .Values.bucketName }}/
        {{ end }}
    volumeMounts:
    - name: local-dir
      mountPath: /local-data
    - name: data-vol
      mountPath: /data
  volumes:
  - name: local-dir
    emptyDir: {}
  - name: data-vol
    {{- if .Values.createUsingGcsfuse }}
    csi:
      driver: gcsfuse.csi.storage.gke.io
      volumeAttributes:
        bucketName: {{ .Values.bucketName }}
        mountOptions: "{{ .Values.gcsfuse.mountOptions }}"
        skipCSIBucketAccessCheck: "true"
    {{- else }}
    emptyDir: {}
    {{- end }}
